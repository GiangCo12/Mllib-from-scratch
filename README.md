<h1 align="center"> Machine Learning Library from Scratch with Python</h1>

## üëã Introduction

In this project, I will "re-built from scratch" state-of-the-art algorithms in ML/DL, but using only Python language. I will use **NumPy library** for better performance on matrix calculation.

One thing you need to know that, I make this project **just for learning and understanding algorithms deeply**, not suitable to apply in real-world problems. I still recommend using many other SOTA libraries for building models.


## üë§ Contributors
**I would like to express my sincere thanks to the these wonderful people who have contributed to this library with me:**

- Giang Nguyen. (owner)
- Tung Nguyen. (contributor)


## üìù Libraries

### A. Classification
1. **Logistic Regression** | Document, [Code](https://github.com/GiangCo12/Mllib-from-scratch/blob/main/class%C3%ACication/LogisticRegression.py)
2. **Naive Bayes**| Document, [Code](https://github.com/GiangCo12/Mllib-from-scratch/blob/main/class%C3%ACication/NaiveBayes.py)
3. **K-Nearest Neighbors (KNN)** | Document, [Code](https://github.com/GiangCo12/Mllib-from-scratch/blob/main/class%C3%ACication/KNN.py)
4. **Decision Tree** | Document, [Code](https://github.com/GiangCo12/Mllib-from-scratch/blob/main/class%C3%ACication/DecisionTreeClassifier.py)
5. **Support Vector Machine (SVM)** | Document, [Code](https://github.com/GiangCo12/Mllib-from-scratch/blob/main/class%C3%ACication/SupportVectorMachine.py)
6. Random Forest
7. Softmax Regression

### B. Regression
1. **Linear Regression** | Document, [Code](https://github.com/GiangCo12/Mllib-from-scratch/blob/main/regression/LinearRegression.py)
2. Ridge Regression
3. Lasso Regression
4. Decision Tree for Regression
5. Random Forest for Regression
6. K-Nearest Neighbors for Regression
7. Support Vector Regression
8. Gaussian Regression
9. Polynomial Regression

### C. Clustering
1. **K-Means** | Document, [Code](https://github.com/GiangCo12/Mllib-from-scratch/blob/main/Cluster/KMeans.py)
2. DBSCAN
3. Mean Shift
4. OPTICS
5. Spectral Clustering
6. Mixture of Gaussians
7. Affinity Propagation
8. Agglomerative Clustering
9. BIRCH

### D. Dimensionality reduction
1. **Principal Components Analysis (PCA)** | Document, [Code](https://github.com/GiangCo12/Mllib-from-scratch/blob/main/Decomposition/PCA.py)
2. **Factor Analysis (FA)** | Document, [Code](https://github.com/GiangCo12/Mllib-from-scratch/blob/main/Decomposition/FactorAnalysis.py)
3. **Linear Discriminant Analysis (LDA)** | [Document](https://github.com/GiangCo12/Mllib-from-scratch/blob/main/Decomposition/LDA.md), [Code](https://github.com/GiangCo12/Mllib-from-scratch/blob/main/Decomposition/LDA.py)
4. Truncated SVD
5. Kernel PCA
6. t-Distributed Stochastic Neighbor Embedding (t-SNE)
7. Multidimensional Scaling (MDS)
8. Isomap
